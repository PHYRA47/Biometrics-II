<div align="center">
  <h1><strong> ğŸ‘¤Biometrics Skill 3: Facial Expression Estimation </strong></h1>
  
  https://github.com/user-attachments/assets/52b92302-bcdb-403b-9580-960e7f4ee091
</div>

This repository contains a Python-based GUI application for real-time and image-based face emotion recognition, as part of the Biometrics II course assignment.

## âœ¨ Key Features

- ğŸ§  **Multiple Emotion Recognition Models**: custome `MobileNetV2` and  Sequential CNN models, and easy integration of additional models for enhanced flexibility.

- ğŸ–¼ï¸ **Multiple Recognition Modes**: Upload and analyze images for emotion detection, use real-time webcam feed for live emotion recognition, and process multiple faces in a single frame.

- ğŸ¨ **Emotion Visualization**: Annotated faces with emotion labels and color-coded bounding boxes.

- ğŸ–¥ï¸ **Modern User Interface**: Clean and intuitive PyQt5-based GUI with tabbed navigation for switching between image upload and webcam modes.

## ğŸ” How It Works & ğŸ›ï¸ Technical Details

The system uses a combination of advanced techniques and tools to deliver accurate and efficient emotion recognition:

- ğŸ¯ **Face Detection**:  
  Utilizes OpenCV's Haar Cascade Classifier for robust and reliable face detection in images and video streams.

- ğŸ§  **Emotion Classification**:  
  Employs deep learning models for precise emotion classification:  
  - `MobileNetV2`: A pre-trained model fine-tuned specifically for emotion recognition.  
  - `Sequential CNN`: A custom CNN model trained on emotion datasets for lightweight and efficient performance.  

- ğŸ­ **Emotion Categories**:  
  Detects and classifies emotions into seven categories:  
  Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral.  

- ğŸ¨ **Image Processing & Annotation**:  
  Leverages OpenCV for image processing, face annotation, and visualization of results with color-coded bounding boxes and labels.  

- ğŸ–¥ï¸ **Graphical Interface**:  
  Built with PyQt5, providing a clean, intuitive, and user-friendly GUI for seamless interaction and navigation. 

## ğŸ“ Requirements

To run this project, ensure you have the following installed:

- **Python 3.9+**  
- **OpenCV**: For image processing and face detection.  
- **TensorFlow==2.10**: For loading and using deep learning models.  
- **PyQt5**: For the graphical user interface.  
- **NumPy==1.26**: For numerical operations and array handling.  

Install the required dependencies using pip:

```bash
pip install opencv-python tensorflow==2.10 pyqt5 numpy<2
```
Alternatively:

```bash
pip install -r requirements.txt
```

## ğŸ“‚ **Project Structure**
```
assets/
models/
â”œâ”€â”€ mobilenetv2/
â”‚ â”œâ”€â”€ mobilenetv2_history.npz       # Training history for MobileNetV2
â”‚ â”œâ”€â”€ mobilenetv2.h5                # MobileNetV2 model weights
â”‚ â””â”€â”€ mobilenetv2.keras
â”œâ”€â”€ sequentialCNN/
â”‚ â””â”€â”€ sequentialCNN.h5
scripts/
â”œâ”€â”€ evaluate_mobilenetv2.ipynb      # Notebook for evaluating MobileNetV2
â”œâ”€â”€ evaluate_sequentialCNN.ipynb    # Notebook for evaluating Sequential CNN
â”œâ”€â”€ preprocess.py                   # Script for preprocessing data
â”œâ”€â”€ training.py                     # Script for training models
â”œâ”€â”€ webcam_mobilenetv2.py           # Webcam implementation for MobileNetV2
â””â”€â”€ webcam_sequentialCNN.py         # Webcam implementation for Sequential CNN
src/
â”œâ”€â”€ EmotionRecognizer.py
â”œâ”€â”€ FERTab.py
â”œâ”€â”€ MainWindow.py
â”œâ”€â”€ complete_main.py
â””â”€â”€ main.py                         # Entry for the application 
README.md
requirements.txt
```